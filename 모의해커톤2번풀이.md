# 1. 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¸”ëŸ¬ì˜¤ê¸°

### ğŸ”¹ ====================================================================

> ğŸ’¬ ì„ì‹  ì„±ê³µ ì—¬ë¶€ ì˜ˆì¸¡ ëª¨ë¸ - ì„±ëŠ¥ í–¥ìƒ ë²„ì „

> ğŸ’¬ 1ë‹¨ê³„: ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°

### ğŸ”¹ ====================================================================


> ğŸ’¬ ê¸°ë³¸ ë°ì´í„° ì²˜ë¦¬ ë° ìˆ˜ì¹˜ ì—°ì‚°

```python
import pandas as pd
```
- `pandas as pd`: ë°ì´í„°í”„ë ˆì„ í˜•íƒœë¡œ í…Œì´ë¸” ë°ì´í„°ë¥¼ ì¡°ì‘í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. `pd`ëŠ” ë³´í†µì˜ ì•½ì¹­ì…ë‹ˆë‹¤.
```python
import numpy as np
```
- `numpy as np`: ë²¡í„°, í–‰ë ¬, ìˆ˜ì¹˜ ê³„ì‚°ì— íŠ¹í™”ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ë‹¤ì°¨ì› ë°°ì—´ ê°ì²´(`ndarray`)ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
```python
import sklearn
```
```python
import warnings
```
- `warnings`: ê²½ê³  ë©”ì‹œì§€ë¥¼ ì œì–´í•  ìˆ˜ ìˆëŠ” íŒŒì´ì¬ ê¸°ë³¸ ëª¨ë“ˆì…ë‹ˆë‹¤.
```python
warnings.filterwarnings('ignore')
```
- `warnings.filterwarnings('ignore')`: ì‹¤í–‰ ì¤‘ ë‚˜íƒ€ë‚˜ëŠ” ê²½ê³  ë©”ì‹œì§€ë¥¼ ë¬´ì‹œí•©ë‹ˆë‹¤.

> ğŸ’¬ ì‹œê°í™”

```python
import matplotlib
```
- `matplotlib.pyplot as plt`: ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•œ 2D í”Œë¡œíŒ… ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
```python
import matplotlib.pyplot as plt
```
- `matplotlib.pyplot as plt`: ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•œ 2D í”Œë¡œíŒ… ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
```python
import seaborn as sns
```
- `seaborn as sns`: í†µê³„ì  ì‹œê°í™”ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, matplotlibë³´ë‹¤ ë” ë³´ê¸° ì¢‹ì€ ì‹œê°í™”ë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
```python
import plotly.express as px
```
- `plotly`: ì¸í„°ë™í‹°ë¸Œí•œ ì›¹ ê¸°ë°˜ ê·¸ë˜í”„ ì‹œê°í™”ë¥¼ ì§€ì›í•˜ëŠ” ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
```python
import plotly.graph_objects as go
```
- `plotly`: ì¸í„°ë™í‹°ë¸Œí•œ ì›¹ ê¸°ë°˜ ê·¸ë˜í”„ ì‹œê°í™”ë¥¼ ì§€ì›í•˜ëŠ” ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.
```python
from plotly.subplots import make_subplots
```
- `plotly`: ì¸í„°ë™í‹°ë¸Œí•œ ì›¹ ê¸°ë°˜ ê·¸ë˜í”„ ì‹œê°í™”ë¥¼ ì§€ì›í•˜ëŠ” ê³ ê¸‰ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

> ğŸ’¬ ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§

```python
from sklearn.preprocessing import (
```
```python
    StandardScaler, RobustScaler, MinMaxScaler,
```
```python
    LabelEncoder, OrdinalEncoder, OneHotEncoder,
```
```python
    TargetEncoder, PowerTransformer, QuantileTransformer
```
```python
)
```
```python
from sklearn.feature_selection import (
```
```python
    SelectKBest, f_classif, chi2, mutual_info_classif,
```
```python
    RFE, RFECV, SelectFromModel
```
```python
)
```
```python
from sklearn.decomposition import PCA, TruncatedSVD
```
```python
from sklearn.manifold import TSNE
```
> ğŸ’¬ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (IterativeImputerëŠ” experimentalì´ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬)

```python
from sklearn.impute import SimpleImputer, KNNImputer
```
```python
try:
```
```python
    from sklearn.experimental import enable_iterative_imputer
```
```python
    from sklearn.impute import IterativeImputer
```
```python
    print("âœ“ IterativeImputer ì‚¬ìš© ê°€ëŠ¥")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
except ImportError:
```
```python
    print("âš  IterativeImputerëŠ” sklearn 0.21+ ë²„ì „ì—ì„œ ì‚¬ìš© ê°€ëŠ¥")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ëª¨ë¸ë“¤ - íŠ¸ë¦¬ ê¸°ë°˜

```python
from sklearn.ensemble import (
```
```python
    RandomForestClassifier, ExtraTreesClassifier,
```
```python
    GradientBoostingClassifier, AdaBoostClassifier,
```
```python
    VotingClassifier, BaggingClassifier
```
```python
)
```
```python
from sklearn.tree import DecisionTreeClassifier
```

> ğŸ’¬ ëª¨ë¸ë“¤ - ê¸°íƒ€ ì•Œê³ ë¦¬ì¦˜

```python
from sklearn.linear_model import LogisticRegression, RidgeClassifier
```
```python
from sklearn.svm import SVC
```
```python
from sklearn.neighbors import KNeighborsClassifier
```
```python
from sklearn.naive_bayes import GaussianNB
```
```python
from sklearn.neural_network import MLPClassifier
```

> ğŸ’¬ ê³ ì„±ëŠ¥ ë¶€ìŠ¤íŒ… ëª¨ë¸ë“¤

```python
try:
```
```python
    import lightgbm as lgb
```
```python
    print("âœ“ LightGBM ì‚¬ìš© ê°€ëŠ¥")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
except ImportError:
```
```python
    print("âš  LightGBM ì„¤ì¹˜ í•„ìš”: pip install lightgbm")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
try:
```
```python
    import xgboost as xgb
```
```python
    print("âœ“ XGBoost ì‚¬ìš© ê°€ëŠ¥")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
except ImportError:
```
```python
    print("âš  XGBoost ì„¤ì¹˜ í•„ìš”: pip install xgboost")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
try:
```
```python
    import catboost as cb
```
```python
    print("âœ“ CatBoost ì‚¬ìš© ê°€ëŠ¥")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
except ImportError:
```
```python
    print("âš  CatBoost ì„¤ì¹˜ í•„ìš”: pip install catboost")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ëª¨ë¸ í‰ê°€ ë° ê²€ì¦

```python
from sklearn.model_selection import (
```
- `sklearn.model_selection`: í•™ìŠµìš©/ê²€ì¦ìš© ë°ì´í„° ë¶„í• , êµì°¨ ê²€ì¦, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë“±ì„ ì§€ì›í•©ë‹ˆë‹¤.
```python
    train_test_split, cross_val_score, StratifiedKFold,
```
```python
    GridSearchCV, RandomizedSearchCV, validation_curve,
```
```python
    learning_curve
```
```python
)
```
```python
from sklearn.metrics import (
```
- `sklearn.metrics`: ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•˜ê¸° ìœ„í•œ ë‹¤ì–‘í•œ ì§€í‘œë“¤ì„ ì œê³µí•©ë‹ˆë‹¤ (ì˜ˆ: ì •í™•ë„, ì •ë°€ë„, F1 score ë“±).
```python
    accuracy_score, precision_score, recall_score, f1_score,
```
```python
    roc_auc_score, roc_curve, precision_recall_curve,
```
```python
    confusion_matrix, classification_report,
```
```python
    log_loss, average_precision_score
```
```python
)
```

> ğŸ’¬ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”

```python
try:
```
```python
    import optuna
```
```python
    print("âœ“ Optuna ì‚¬ìš© ê°€ëŠ¥")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
except ImportError:
```
```python
    print("âš  Optuna ì„¤ì¹˜ í•„ìš”: pip install optuna")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ëª¨ë¸ í•´ì„

```python
try:
```
```python
    import shap
```
```python
    print("âœ“ SHAP ì‚¬ìš© ê°€ëŠ¥")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
except ImportError:
```
```python
    print("âš  SHAP ì„¤ì¹˜ í•„ìš”: pip install shap")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬

```python
try:
```
```python
    from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE
```
```python
    from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours
```
```python
    from imblearn.combine import SMOTEENN, SMOTETomek
```
```python
    print("âœ“ imbalanced-learn ì‚¬ìš© ê°€ëŠ¥")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
except ImportError:
```
```python
    print("âš  imbalanced-learn ì„¤ì¹˜ í•„ìš”: pip install imbalanced-learn")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ìë™í™”ëœ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§

```python
try:
```
```python
    import featuretools as ft
```
```python
    print("âœ“ Featuretools ì‚¬ìš© ê°€ëŠ¥")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
except ImportError:
```
```python
    print("âš  Featuretools ì„¤ì¹˜ í•„ìš”: pip install featuretools")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ê¸°íƒ€ ìœ í‹¸ë¦¬í‹°

```python
import itertools
```
```python
from collections import Counter
```
```python
import pickle
```
```python
import joblib
```
```python
from datetime import datetime
```
```python
import os
```
```python
import gc
```
```python
from scipy import stats
```
```python
from scipy.stats import chi2_contingency
```

> ğŸ’¬ ì„¤ì •

```python
matplotlib.rcParams['figure.figsize'] = (10, 6)
```
```python
plt.style.use('default')
```
```python
sns.set_palette("husl")
```
```python
pd.set_option('display.max_columns', None)
```
```python
pd.set_option('display.width', None)
```
```python
pd.set_option('display.max_colwidth', None)
```

> ğŸ’¬ ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ì„¤ì •

```python
RANDOM_STATE = 42
```
```python
np.random.seed(RANDOM_STATE)
```

```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸš€ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"ğŸ“Š Pandas: {pd.__version__}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"ğŸ”¢ NumPy: {np.__version__}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"ğŸ¤– Scikit-learn: {sklearn.__version__}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"ğŸ“ˆ Matplotlib: {matplotlib.__version__}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"ğŸ¨ Seaborn: {sns.__version__}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("âœ… 1ë‹¨ê³„ ì™„ë£Œ: ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ”„ ë‹¤ìŒ ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
# 2. 2ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)

### ğŸ”¹ ====================================================================

> ğŸ’¬ ì„ì‹  ì„±ê³µ ì—¬ë¶€ ì˜ˆì¸¡ ëª¨ë¸ - ì„±ëŠ¥ í–¥ìƒ ë²„ì „

> ğŸ’¬ 2ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)

### ğŸ”¹ ====================================================================


```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ“‚ 2ë‹¨ê³„: ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰ì  ë°ì´í„° ë¶„ì„ ì‹œì‘")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 1. ë°ì´í„° ë¡œë“œ

```python
print("ğŸ“Š ë°ì´í„° ë¡œë”© ì¤‘...")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
train = pd.read_csv('/content/train.csv')
```
```python
test = pd.read_csv('/content/test.csv')
```

```python
print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ğŸ“ˆ Train ë°ì´í„°: {train.shape}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ğŸ“‰ Test ë°ì´í„°: {test.shape}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 2. ê¸°ë³¸ ë°ì´í„° ì •ë³´

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ“‹ ê¸°ë³¸ ë°ì´í„° ì •ë³´")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print("\nğŸ” Train ë°ì´í„° ê¸°ë³¸ ì •ë³´:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   - í–‰ ìˆ˜: {train.shape[0]:,}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   - ì—´ ìˆ˜: {train.shape[1]:,}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {train.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print("\nğŸ” Test ë°ì´í„° ê¸°ë³¸ ì •ë³´:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   - í–‰ ìˆ˜: {test.shape[0]:,}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   - ì—´ ìˆ˜: {test.shape[1]:,}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {test.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 3. ì»¬ëŸ¼ ì •ë³´

```python
print(f"\nğŸ“ ì „ì²´ ì»¬ëŸ¼ ëª©ë¡ ({len(train.columns)}ê°œ):")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for i, col in enumerate(train.columns, 1):
```
```python
    print(f"   {i:2d}. {col}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 4. ë°ì´í„° íƒ€ì… í™•ì¸

```python
print(f"\nğŸ·ï¸  ë°ì´í„° íƒ€ì… ë¶„í¬:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
train_dtypes = train.dtypes.value_counts()
```
```python
for dtype, count in train_dtypes.items():
```
```python
    print(f"   {dtype}: {count}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 5. ID ì»¬ëŸ¼ í™•ì¸ ë° ì œê±°

```python
if 'ID' in train.columns:
```
```python
    print(f"\nğŸ”‘ ID ì»¬ëŸ¼ ë°œê²¬ - ì œê±° ì§„í–‰")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
    train_ids = train['ID'].copy()
```
```python
    test_ids = test['ID'].copy()
```
```python
    train = train.drop('ID', axis=1)
```
```python
    test = test.drop('ID', axis=1)
```
```python
    print(f"   âœ… ID ì»¬ëŸ¼ ì œê±° ì™„ë£Œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
    print(f"   ğŸ“ˆ Train: {train.shape}, Test: {test.shape}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 6. íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„ë¦¬

```python
target_col = 'ì„ì‹  ì„±ê³µ ì—¬ë¶€'
```
```python
if target_col in train.columns:
```
```python
    X = train.drop(target_col, axis=1)
```
```python
    y = train[target_col]
```
```python
    print(f"\nğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ '{target_col}' ë¶„ë¦¬ ì™„ë£Œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
    print(f"   ğŸ“Š íŠ¹ì„± ë°ì´í„°: {X.shape}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
    print(f"   ğŸ¯ íƒ€ê²Ÿ ë°ì´í„°: {y.shape}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
else:
```
```python
    print(f"\nâŒ íƒ€ê²Ÿ ë³€ìˆ˜ '{target_col}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 7. íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬ ë¶„ì„

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬ ë¶„ì„")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
target_counts = y.value_counts().sort_index()
```
```python
target_props = y.value_counts(normalize=True).sort_index()
```

```python
print("ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for class_val in sorted(y.unique()):
```
```python
    count = target_counts[class_val]
```
```python
    prop = target_props[class_val]
```
```python
    print(f"   í´ë˜ìŠ¤ {class_val}: {count:,}ê°œ ({prop:.2%})")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ë¶ˆê· í˜• ì •ë„ ê³„ì‚°

```python
imbalance_ratio = target_counts.max() / target_counts.min()
```
```python
print(f"\nâš–ï¸  í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¹„ìœ¨: {imbalance_ratio:.2f}:1")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
if imbalance_ratio > 2:
```
```python
    print("   âš ï¸  ë¶ˆê· í˜• ë°ì´í„° - SMOTE ë“± ìƒ˜í”Œë§ ê¸°ë²• ê³ ë ¤ í•„ìš”")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
else:
```
```python
    print("   âœ… ë¹„êµì  ê· í˜•ì¡íŒ ë°ì´í„°")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 8. ê²°ì¸¡ì¹˜ ë¶„ì„

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ” ê²°ì¸¡ì¹˜ ë¶„ì„")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ Train ë°ì´í„° ê²°ì¸¡ì¹˜

```python
print("ğŸ“ˆ Train ë°ì´í„° ê²°ì¸¡ì¹˜:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
train_missing = X.isnull().sum()
```
```python
train_missing_pct = (train_missing / len(X)) * 100
```
```python
missing_info = pd.DataFrame({
```
```python
    'ê²°ì¸¡ì¹˜_ê°œìˆ˜': train_missing,
```
```python
    'ê²°ì¸¡ì¹˜_ë¹„ìœ¨(%)': train_missing_pct
```
```python
}).sort_values('ê²°ì¸¡ì¹˜_ê°œìˆ˜', ascending=False)
```

> ğŸ’¬ ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼ë§Œ í‘œì‹œ

```python
missing_cols = missing_info[missing_info['ê²°ì¸¡ì¹˜_ê°œìˆ˜'] > 0]
```
```python
if len(missing_cols) > 0:
```
```python
    print(f"   ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼: {len(missing_cols)}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
    print(missing_cols.head(10))
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
else:
```
```python
    print("   âœ… ê²°ì¸¡ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤!")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ Test ë°ì´í„° ê²°ì¸¡ì¹˜

```python
print(f"\nğŸ“‰ Test ë°ì´í„° ê²°ì¸¡ì¹˜:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
test_missing = test.isnull().sum()
```
```python
test_missing_pct = (test_missing / len(test)) * 100
```
```python
test_missing_info = pd.DataFrame({
```
```python
    'ê²°ì¸¡ì¹˜_ê°œìˆ˜': test_missing,
```
```python
    'ê²°ì¸¡ì¹˜_ë¹„ìœ¨(%)': test_missing_pct
```
```python
}).sort_values('ê²°ì¸¡ì¹˜_ê°œìˆ˜', ascending=False)
```

```python
test_missing_cols = test_missing_info[test_missing_info['ê²°ì¸¡ì¹˜_ê°œìˆ˜'] > 0]
```
```python
if len(test_missing_cols) > 0:
```
```python
    print(f"   ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ì»¬ëŸ¼: {len(test_missing_cols)}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
    print(test_missing_cols.head(10))
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
else:
```
```python
    print("   âœ… ê²°ì¸¡ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤!")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 9. ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ‘€ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print("ğŸ“Š Train ë°ì´í„° ìƒìœ„ 5í–‰:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(train.head())
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print(f"\nğŸ“Š Train ë°ì´í„° ê¸°ìˆ í†µê³„ (ìˆ˜ì¹˜í˜• ì»¬ëŸ¼):")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
numeric_cols = X.select_dtypes(include=[np.number]).columns
```
```python
if len(numeric_cols) > 0:
```
```python
    print(X[numeric_cols].describe())
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
else:
```
```python
    print("   ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print("\n" + "="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("âœ… 2ë‹¨ê³„ ì™„ë£Œ: ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ë¶„ì„")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ”„ ë‹¤ìŒ: ë°ì´í„° íƒ€ì…ë³„ ìƒì„¸ ë¶„ì„ ë° ì‹œê°í™”")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
# 3. 3ë‹¨ê³„: ìƒì„¸ EDA ë° ì‹œê°í™”

### ğŸ”¹ ====================================================================

> ğŸ’¬ ì„ì‹  ì„±ê³µ ì—¬ë¶€ ì˜ˆì¸¡ ëª¨ë¸ - ì„±ëŠ¥ í–¥ìƒ ë²„ì „

> ğŸ’¬ 3ë‹¨ê³„: ìƒì„¸ EDA ë° ì‹œê°í™”

### ğŸ”¹ ====================================================================


```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ“Š 3ë‹¨ê³„: ìƒì„¸ EDA ë° ì‹œê°í™” ë¶„ì„ ì‹œì‘")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ë°ì´í„° ëª…ì„¸ì—ì„œ íŒŒì•…í•œ íŠ¹ì„± ë¶„ë¥˜

```python
categorical_features = [
```
```python
    "ì‹œìˆ  ì‹œê¸° ì½”ë“œ", "ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´", "ì‹œìˆ  ìœ í˜•", "ë°°ë€ ìê·¹ ì—¬ë¶€", "ë°°ë€ ìœ ë„ ìœ í˜•",
```
```python
    "ë‹¨ì¼ ë°°ì•„ ì´ì‹ ì—¬ë¶€", "ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€", "ì°©ìƒ ì „ ìœ ì „ ì§„ë‹¨ ì‚¬ìš© ì—¬ë¶€",
```
```python
    "ë‚¨ì„± ì£¼ ë¶ˆì„ ì›ì¸", "ë‚¨ì„± ë¶€ ë¶ˆì„ ì›ì¸", "ì—¬ì„± ì£¼ ë¶ˆì„ ì›ì¸", "ì—¬ì„± ë¶€ ë¶ˆì„ ì›ì¸",
```
```python
    "ë¶€ë¶€ ì£¼ ë¶ˆì„ ì›ì¸", "ë¶€ë¶€ ë¶€ ë¶ˆì„ ì›ì¸", "ë¶ˆëª…í™• ë¶ˆì„ ì›ì¸", "ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜",
```
```python
    "ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸", "ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• ", "ë¶ˆì„ ì›ì¸ - ì—¬ì„± ìš”ì¸",
```
```python
    "ë¶ˆì„ ì›ì¸ - ìê¶ê²½ë¶€ ë¬¸ì œ", "ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦", "ë¶ˆì„ ì›ì¸ - ì •ì ë†ë„",
```
```python
    "ë¶ˆì„ ì›ì¸ - ì •ì ë©´ì—­í•™ì  ìš”ì¸", "ë¶ˆì„ ì›ì¸ - ì •ì ìš´ë™ì„±", "ë¶ˆì„ ì›ì¸ - ì •ì í˜•íƒœ",
```
```python
    "ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ", "ì´ ì‹œìˆ  íšŸìˆ˜", "í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜", "IVF ì‹œìˆ  íšŸìˆ˜",
```
```python
    "DI ì‹œìˆ  íšŸìˆ˜", "ì´ ì„ì‹  íšŸìˆ˜", "IVF ì„ì‹  íšŸìˆ˜", "DI ì„ì‹  íšŸìˆ˜", "ì´ ì¶œì‚° íšŸìˆ˜",
```
```python
    "IVF ì¶œì‚° íšŸìˆ˜", "DI ì¶œì‚° íšŸìˆ˜", "ë‚œì ì¶œì²˜", "ì •ì ì¶œì²˜", "ë‚œì ê¸°ì¦ì ë‚˜ì´",
```
```python
    "ì •ì ê¸°ì¦ì ë‚˜ì´", "ë™ê²° ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ì‹ ì„  ë°°ì•„ ì‚¬ìš© ì—¬ë¶€", "ê¸°ì¦ ë°°ì•„ ì‚¬ìš© ì—¬ë¶€",
```
```python
    "ëŒ€ë¦¬ëª¨ ì—¬ë¶€", "PGD ì‹œìˆ  ì—¬ë¶€", "PGS ì‹œìˆ  ì—¬ë¶€"
```
```python
]
```

```python
numerical_features = [
```
```python
    "ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜", "íŠ¹ì • ì‹œìˆ  ìœ í˜•", "ì´ ìƒì„± ë°°ì•„ ìˆ˜",
```
```python
    "ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜", "ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜", "ì´ì‹ëœ ë°°ì•„ ìˆ˜",
```
```python
    "ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜", "ì €ì¥ëœ ë°°ì•„ ìˆ˜", "ë¯¸ì„¸ì£¼ì… í›„ ì €ì¥ëœ ë°°ì•„ ìˆ˜",
```
```python
    "í•´ë™ëœ ë°°ì•„ ìˆ˜", "í•´ë™ ë‚œì ìˆ˜", "ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜", "ì €ì¥ëœ ì‹ ì„  ë‚œì ìˆ˜",
```
```python
    "í˜¼í•©ëœ ë‚œì ìˆ˜", "íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜", "ê¸°ì¦ì ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜",
```
```python
    "ë‚œì ì±„ì·¨ ê²½ê³¼ì¼", "ë‚œì í•´ë™ ê²½ê³¼ì¼", "ë‚œì í˜¼í•© ê²½ê³¼ì¼", "ë°°ì•„ ì´ì‹ ê²½ê³¼ì¼", "ë°°ì•„ í•´ë™ ê²½ê³¼ì¼"
```
```python
]
```

> ğŸ’¬ 1. ê²°ì¸¡ì¹˜ íŒ¨í„´ ìƒì„¸ ë¶„ì„

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ” ê²°ì¸¡ì¹˜ íŒ¨í„´ ìƒì„¸ ë¶„ì„")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ë³„ ë³€ìˆ˜ ë¶„ë¥˜

```python
missing_analysis = pd.DataFrame({
```
```python
    'column': X.columns,
```
```python
    'missing_count': X.isnull().sum(),
```
```python
    'missing_pct': (X.isnull().sum() / len(X)) * 100
```
```python
}).sort_values('missing_pct', ascending=False)
```

> ğŸ’¬ ê²°ì¸¡ì¹˜ íŒ¨í„´ë³„ ë¶„ë¥˜

```python
high_missing = missing_analysis[missing_analysis['missing_pct'] > 80]
```
```python
medium_missing = missing_analysis[(missing_analysis['missing_pct'] > 20) & (missing_analysis['missing_pct'] <= 80)]
```
```python
low_missing = missing_analysis[(missing_analysis['missing_pct'] > 0) & (missing_analysis['missing_pct'] <= 20)]
```
```python
no_missing = missing_analysis[missing_analysis['missing_pct'] == 0]
```

```python
print(f"ğŸ“Š ê²°ì¸¡ì¹˜ íŒ¨í„´ë³„ ë³€ìˆ˜ ë¶„ë¥˜:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ğŸ”´ ê³ ê²°ì¸¡ (80%+): {len(high_missing)}ê°œ ë³€ìˆ˜")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ğŸŸ¡ ì¤‘ê²°ì¸¡ (20-80%): {len(medium_missing)}ê°œ ë³€ìˆ˜")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ğŸŸ¢ ì €ê²°ì¸¡ (0-20%): {len(low_missing)}ê°œ ë³€ìˆ˜")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   âœ… ê²°ì¸¡ ì—†ìŒ: {len(no_missing)}ê°œ ë³€ìˆ˜")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print(f"\nğŸ”´ ê³ ê²°ì¸¡ ë³€ìˆ˜ë“¤ (ì œê±° ê³ ë ¤):")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for _, row in high_missing.iterrows():
```
```python
    print(f"   - {row['column']}: {row['missing_pct']:.1f}%")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print(f"\nğŸŸ¡ ì¤‘ê²°ì¸¡ ë³€ìˆ˜ë“¤ (íŠ¹ë³„ ì²˜ë¦¬ í•„ìš”):")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for _, row in medium_missing.iterrows():
```
```python
    print(f"   - {row['column']}: {row['missing_pct']:.1f}%")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 2. íƒ€ê²Ÿ ë³€ìˆ˜ì™€ì˜ ê´€ê³„ ë¶„ì„ (ë²”ì£¼í˜• ë³€ìˆ˜)

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ¯ ë²”ì£¼í˜• ë³€ìˆ˜ì™€ íƒ€ê²Ÿì˜ ê´€ê³„ ë¶„ì„")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ê²°ì¸¡ì¹˜ê°€ ì ì€ ì¤‘ìš”í•œ ë²”ì£¼í˜• ë³€ìˆ˜ë“¤ ì„ ë³„

```python
important_categorical = [
```
```python
    "ì‹œìˆ  ì‹œê¸° ì½”ë“œ", "ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´", "ì‹œìˆ  ìœ í˜•", "ë°°ë€ ìê·¹ ì—¬ë¶€",
```
```python
    "ë°°ë€ ìœ ë„ ìœ í˜•", "ë¶ˆì„ ì›ì¸ - ë‚¨ì„± ìš”ì¸", "ë¶ˆì„ ì›ì¸ - ë°°ë€ ì¥ì• ",
```
```python
    "ë¶ˆì„ ì›ì¸ - ë‚œê´€ ì§ˆí™˜", "ë¶ˆì„ ì›ì¸ - ìê¶ë‚´ë§‰ì¦", "ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ ",
```
```python
    "ë‚œì ì¶œì²˜", "ì •ì ì¶œì²˜"
```
```python
]
```

```python
target_categorical_analysis = {}
```
```python
for col in important_categorical:
```
```python
    if col in X.columns:
```
> ğŸ’¬ íƒ€ê²Ÿë³„ ë¶„í¬ ê³„ì‚°

```python
        crosstab = pd.crosstab(X[col], y, normalize='index')
```
```python
        success_rate = crosstab[1] if 1 in crosstab.columns else pd.Series()
```
```python
        target_categorical_analysis[col] = {
```
```python
            'success_rates': success_rate,
```
```python
            'unique_count': X[col].nunique(),
```
```python
            'most_common': X[col].value_counts().head(3)
```
```python
        }
```

```python
print("ğŸ“Š ì£¼ìš” ë²”ì£¼í˜• ë³€ìˆ˜ë³„ ì„ì‹  ì„±ê³µë¥ :")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for col, analysis in target_categorical_analysis.items():
```
```python
    print(f"\nğŸ”¸ {col}:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
    print(f"   ì¹´í…Œê³ ë¦¬ ìˆ˜: {analysis['unique_count']}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
    if len(analysis['success_rates']) > 0:
```
```python
        print(f"   ìµœê³  ì„±ê³µë¥ : {analysis['success_rates'].max():.3f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
        print(f"   ìµœì € ì„±ê³µë¥ : {analysis['success_rates'].min():.3f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
        print(f"   ì„±ê³µë¥  í¸ì°¨: {analysis['success_rates'].std():.3f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 3. ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„í¬ ë¶„ì„

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ“ˆ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ë¶„í¬ ë¶„ì„")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ê²°ì¸¡ì¹˜ê°€ ì ì€ ì¤‘ìš”í•œ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤

```python
important_numerical = [
```
```python
    "ì´ ìƒì„± ë°°ì•„ ìˆ˜", "ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜", "ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜",
```
```python
    "ì´ì‹ëœ ë°°ì•„ ìˆ˜", "ë¯¸ì„¸ì£¼ì… ë°°ì•„ ì´ì‹ ìˆ˜", "ì €ì¥ëœ ë°°ì•„ ìˆ˜",
```
```python
    "ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜", "í˜¼í•©ëœ ë‚œì ìˆ˜", "íŒŒíŠ¸ë„ˆ ì •ìì™€ í˜¼í•©ëœ ë‚œì ìˆ˜"
```
```python
]
```

```python
print("ğŸ“Š ì£¼ìš” ìˆ˜ì¹˜í˜• ë³€ìˆ˜ í†µê³„:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for col in important_numerical:
```
```python
    if col in X.columns:
```
```python
        col_data = X[col].dropna()
```
```python
        if len(col_data) > 0:
```
```python
            print(f"\nğŸ”¸ {col}:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
            print(f"   í‰ê· : {col_data.mean():.2f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
            print(f"   ì¤‘ìœ„ìˆ˜: {col_data.median():.2f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
            print(f"   í‘œì¤€í¸ì°¨: {col_data.std():.2f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
            print(f"   ìµœëŒ“ê°’: {col_data.max():.0f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
            print(f"   0ì¸ ë¹„ìœ¨: {(col_data == 0).mean():.2%}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ íƒ€ê²Ÿë³„ í‰ê·  ë¹„êµ

```python
            target_0_mean = X.loc[y == 0, col].mean()
```
```python
            target_1_mean = X.loc[y == 1, col].mean()
```
```python
            print(f"   ì‹¤íŒ¨êµ° í‰ê· : {target_0_mean:.2f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
            print(f"   ì„±ê³µêµ° í‰ê· : {target_1_mean:.2f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
            print(f"   ì°¨ì´: {target_1_mean - target_0_mean:.2f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 4. ìƒê´€ê´€ê³„ ë¶„ì„

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ”— ë³€ìˆ˜ ê°„ ìƒê´€ê´€ê³„ ë¶„ì„")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ ê°„ì˜ ìƒê´€ê´€ê³„

```python
numeric_data = X[important_numerical].select_dtypes(include=[np.number])
```
```python
correlation_matrix = numeric_data.corr()
```

> ğŸ’¬ ë†’ì€ ìƒê´€ê´€ê³„ ì°¾ê¸°

```python
high_corr_pairs = []
```
```python
for i in range(len(correlation_matrix.columns)):
```
```python
    for j in range(i+1, len(correlation_matrix.columns)):
```
```python
        corr_value = correlation_matrix.iloc[i, j]
```
```python
        if abs(corr_value) > 0.7:  # 0.7 ì´ìƒì˜ ìƒê´€ê´€ê³„
```
```python
            high_corr_pairs.append({
```
```python
                'var1': correlation_matrix.columns[i],
```
```python
                'var2': correlation_matrix.columns[j],
```
```python
                'correlation': corr_value
```
```python
            })
```

```python
print(f"ğŸ“Š ë†’ì€ ìƒê´€ê´€ê³„ (|r| > 0.7) ë³€ìˆ˜ ìŒ: {len(high_corr_pairs)}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for pair in high_corr_pairs:
```
```python
    print(f"   {pair['var1']} â†” {pair['var2']}: {pair['correlation']:.3f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 5. ì´ìƒì¹˜ íƒì§€

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ“Š ì´ìƒì¹˜ íƒì§€ (IQR ë°©ë²•)")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
outlier_summary = {}
```
```python
for col in important_numerical:
```
```python
    if col in X.columns:
```
```python
        col_data = X[col].dropna()
```
```python
        if len(col_data) > 0:
```
```python
            Q1 = col_data.quantile(0.25)
```
```python
            Q3 = col_data.quantile(0.75)
```
```python
            IQR = Q3 - Q1
```
```python
            lower_bound = Q1 - 1.5 * IQR
```
```python
            upper_bound = Q3 + 1.5 * IQR
```

```python
            outliers = col_data[(col_data < lower_bound) | (col_data > upper_bound)]
```
```python
            outlier_pct = len(outliers) / len(col_data) * 100
```

```python
            outlier_summary[col] = {
```
```python
                'count': len(outliers),
```
```python
                'percentage': outlier_pct,
```
```python
                'bounds': (lower_bound, upper_bound)
```
```python
            }
```

```python
print("ğŸ“Š ì´ìƒì¹˜ í˜„í™©:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for col, info in outlier_summary.items():
```
```python
    if info['percentage'] > 5:  # 5% ì´ìƒì¸ ê²½ìš°ë§Œ í‘œì‹œ
```
```python
        print(f"   {col}: {info['count']}ê°œ ({info['percentage']:.1f}%)")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 6. íŠ¹ì„± ì¤‘ìš”ë„ (ìƒí˜¸ì •ë³´ëŸ‰)

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ¯ íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ (ìƒí˜¸ì •ë³´ëŸ‰)")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
from sklearn.feature_selection import mutual_info_classif
```

> ğŸ’¬ ê²°ì¸¡ì¹˜ê°€ ì ì€ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë“¤ë¡œ ìƒí˜¸ì •ë³´ëŸ‰ ê³„ì‚°

```python
clean_numeric_cols = []
```
```python
X_clean_numeric = pd.DataFrame()
```

```python
for col in important_numerical:
```
```python
    if col in X.columns:
```
```python
        col_data = X[col].fillna(X[col].median())  # ì„ì‹œë¡œ ì¤‘ìœ„ìˆ˜ë¡œ ê²°ì¸¡ì¹˜ ì±„ì›€
```
```python
        if col_data.nunique() > 1:  # ìƒìˆ˜ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
```
```python
            X_clean_numeric[col] = col_data
```
```python
            clean_numeric_cols.append(col)
```

```python
if len(X_clean_numeric) > 0:
```
```python
    mi_scores = mutual_info_classif(X_clean_numeric, y, random_state=42)
```
```python
    feature_importance = pd.DataFrame({
```
```python
        'feature': clean_numeric_cols,
```
```python
        'importance': mi_scores
```
```python
    }).sort_values('importance', ascending=False)
```

```python
    print("ğŸ“Š ìƒí˜¸ì •ë³´ëŸ‰ ê¸°ë°˜ íŠ¹ì„± ì¤‘ìš”ë„ (Top 10):")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
    for _, row in feature_importance.head(10).iterrows():
```
```python
        print(f"   {row['feature']}: {row['importance']:.4f}")
```

```python
print("\n" + "="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("âœ… 3ë‹¨ê³„ ì™„ë£Œ: ìƒì„¸ EDA ë° ë¶„ì„")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ”„ ë‹¤ìŒ ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ EDA ìš”ì•½ ì •ë³´ ì €ì¥

```python
eda_summary = {
```
```python
    'total_samples': len(X),
```
```python
    'total_features': len(X.columns),
```
```python
    'target_success_rate': y.mean(),
```
```python
    'imbalance_ratio': (y == 0).sum() / (y == 1).sum(),
```
```python
    'high_missing_features': len(high_missing),
```
```python
    'medium_missing_features': len(medium_missing),
```
```python
    'low_missing_features': len(low_missing),
```
```python
    'no_missing_features': len(no_missing),
```
```python
    'high_correlation_pairs': len(high_corr_pairs)
```
```python
}
```

```python
print(f"\nğŸ“‹ EDA ìš”ì•½:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for key, value in eda_summary.items():
```
```python
    print(f"   {key}: {value}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
# 4. 4ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§

### ğŸ”¹ ====================================================================

> ğŸ’¬ ì„ì‹  ì„±ê³µ ì—¬ë¶€ ì˜ˆì¸¡ ëª¨ë¸ - ì„±ëŠ¥ í–¥ìƒ ë²„ì „

> ğŸ’¬ 4ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§

### ğŸ”¹ ====================================================================


```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ”§ 4ë‹¨ê³„: ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì‹œì‘")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 1. ê³ ê²°ì¸¡ë¥  ë³€ìˆ˜ ì œê±° (80% ì´ìƒ)

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ—‘ï¸ ê³ ê²°ì¸¡ë¥  ë³€ìˆ˜ ì œê±°")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ EDAì—ì„œ í™•ì¸ëœ ê³ ê²°ì¸¡ë¥  ë³€ìˆ˜ë“¤

```python
high_missing_cols = [
```
```python
    'ë‚œì í•´ë™ ê²½ê³¼ì¼', 'PGS ì‹œìˆ  ì—¬ë¶€', 'PGD ì‹œìˆ  ì—¬ë¶€',
```
```python
    'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', 'ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜', 'ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'
```
```python
]
```

```python
print(f"ì œê±°í•  ê³ ê²°ì¸¡ë¥  ë³€ìˆ˜: {len(high_missing_cols)}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for col in high_missing_cols:
```
```python
    if col in X.columns:
```
```python
        missing_pct = (X[col].isnull().sum() / len(X)) * 100
```
```python
        print(f"   - {col}: {missing_pct:.1f}% ê²°ì¸¡")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ë³€ìˆ˜ ì œê±°

```python
X_processed = X.drop(columns=[col for col in high_missing_cols if col in X.columns])
```
```python
test_processed = test.drop(columns=[col for col in high_missing_cols if col in test.columns])
```

```python
print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ!")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ì´ì „: {X.shape[1]}ê°œ â†’ í˜„ì¬: {X_processed.shape[1]}ê°œ ë³€ìˆ˜")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 2. ë°ì´í„° íƒ€ì…ë³„ ë¶„ë¥˜

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ“Š ë°ì´í„° íƒ€ì…ë³„ ë³€ìˆ˜ ë¶„ë¥˜")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ë²”ì£¼í˜• ë³€ìˆ˜ (object íƒ€ì… + íŠ¹ì • ìˆ˜ì¹˜í˜•)

```python
categorical_cols = []
```
```python
numerical_cols = []
```

```python
for col in X_processed.columns:
```
```python
    if X_processed[col].dtype == 'object':
```
```python
        categorical_cols.append(col)
```
```python
    elif X_processed[col].nunique() <= 10 and col.endswith(('ì—¬ë¶€', 'ì›ì¸', 'ìœ í˜•', 'íšŸìˆ˜', 'ì¶œì²˜', 'ë‚˜ì´')):
```
```python
        categorical_cols.append(col)
```
```python
    else:
```
```python
        numerical_cols.append(col)
```

```python
print(f"ğŸ“ ë²”ì£¼í˜• ë³€ìˆ˜: {len(categorical_cols)}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"ğŸ“ˆ ìˆ˜ì¹˜í˜• ë³€ìˆ˜: {len(numerical_cols)}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 3. ê²°ì¸¡ì¹˜ ì²˜ë¦¬

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ”§ ê²°ì¸¡ì¹˜ ì²˜ë¦¬")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
X_processed = X_processed.copy()
```
```python
test_processed = test_processed.copy()
```

> ğŸ’¬ ë²”ì£¼í˜• ë³€ìˆ˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ìµœë¹ˆê°’ìœ¼ë¡œ ëŒ€ì²´)

```python
for col in categorical_cols:
```
```python
    if col in X_processed.columns:
```
```python
        missing_count = X_processed[col].isnull().sum()
```
```python
        if missing_count > 0:
```
```python
            mode_value = X_processed[col].mode()[0] if len(X_processed[col].mode()) > 0 else 'Unknown'
```
```python
            X_processed[col] = X_processed[col].fillna(mode_value)
```
```python
            test_processed[col] = test_processed[col].fillna(mode_value)
```
```python
            print(f"   ğŸ“ {col}: {missing_count}ê°œ â†’ '{mode_value}'ë¡œ ëŒ€ì²´")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (ì¤‘ìœ„ìˆ˜ë¡œ ëŒ€ì²´)

```python
for col in numerical_cols:
```
```python
    if col in X_processed.columns:
```
```python
        missing_count = X_processed[col].isnull().sum()
```
```python
        if missing_count > 0:
```
```python
            median_value = X_processed[col].median()
```
```python
            X_processed[col] = X_processed[col].fillna(median_value)
```
```python
            test_processed[col] = test_processed[col].fillna(median_value)
```
```python
            print(f"   ğŸ“ˆ {col}: {missing_count}ê°œ â†’ {median_value}ë¡œ ëŒ€ì²´")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print(f"\nâœ… ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ!")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 4. íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ - ë„ë©”ì¸ ì§€ì‹ í™œìš©

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ§¬ ë„ë©”ì¸ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
def add_engineered_features(df):
```
```python
    """ì˜ë£Œ ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•œ íŠ¹ì„± ìƒì„±"""
```
```python
    df_new = df.copy()
```

> ğŸ’¬ 1. íš¨ìœ¨ì„± ì§€í‘œë“¤

```python
    if 'ì´ ìƒì„± ë°°ì•„ ìˆ˜' in df.columns and 'ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜' in df.columns:
```
### ğŸ”¹ ë°°ì•„ ìƒì„± íš¨ìœ¨ = ìƒì„±ëœ ë°°ì•„ ìˆ˜ / ìˆ˜ì§‘ëœ ë‚œì ìˆ˜

```python
        df_new['ë°°ì•„_ìƒì„±_íš¨ìœ¨'] = df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] / (df['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'] + 1)
```

```python
    if 'ì´ì‹ëœ ë°°ì•„ ìˆ˜' in df.columns and 'ì´ ìƒì„± ë°°ì•„ ìˆ˜' in df.columns:
```
### ğŸ”¹ ë°°ì•„ ì´ì‹ ë¹„ìœ¨ = ì´ì‹ëœ ë°°ì•„ ìˆ˜ / ìƒì„±ëœ ë°°ì•„ ìˆ˜

```python
        df_new['ë°°ì•„_ì´ì‹_ë¹„ìœ¨'] = df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] / (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)
```

```python
    if 'ì €ì¥ëœ ë°°ì•„ ìˆ˜' in df.columns and 'ì´ ìƒì„± ë°°ì•„ ìˆ˜' in df.columns:
```
### ğŸ”¹ ë°°ì•„ ë³´ì¡´ ë¹„ìœ¨ = ì €ì¥ëœ ë°°ì•„ ìˆ˜ / ìƒì„±ëœ ë°°ì•„ ìˆ˜

```python
        df_new['ë°°ì•„_ë³´ì¡´_ë¹„ìœ¨'] = df['ì €ì¥ëœ ë°°ì•„ ìˆ˜'] / (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)
```

> ğŸ’¬ 2. ë¯¸ì„¸ì£¼ì… ê´€ë ¨ ì§€í‘œ

```python
    if 'ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜' in df.columns and 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜' in df.columns:
```
### ğŸ”¹ ë¯¸ì„¸ì£¼ì… ì„±ê³µë¥  = ë¯¸ì„¸ì£¼ì… ìƒì„± ë°°ì•„ / ë¯¸ì„¸ì£¼ì…ëœ ë‚œì

```python
        df_new['ë¯¸ì„¸ì£¼ì…_ì„±ê³µë¥ '] = df['ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜'] / (df['ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜'] + 1)
```

> ğŸ’¬ 3. ì¢…í•© ì¹˜ë£Œ ê°•ë„ ì§€í‘œ

```python
    treatment_intensity_cols = [
```
```python
        'ì´ ì‹œìˆ  íšŸìˆ˜', 'IVF ì‹œìˆ  íšŸìˆ˜', 'DI ì‹œìˆ  íšŸìˆ˜'
```
```python
    ]
```
```python
    available_cols = [col for col in treatment_intensity_cols if col in df.columns]
```
```python
    if available_cols:
```
> ğŸ’¬ ì¹˜ë£Œ ê°•ë„ ì ìˆ˜ (ì¹´í…Œê³ ë¦¬ë¥¼ ìˆ˜ì¹˜ë¡œ ë³€í™˜ í›„ í•©ì‚°)

```python
        treatment_scores = []
```
```python
        for col in available_cols:
```
```python
            if df[col].dtype == 'object':
```
> ğŸ’¬ '0íšŒ', '1íšŒ' ë“±ì„ ìˆ«ìë¡œ ë³€í™˜

```python
                col_numeric = df[col].str.extract(r'(\d+)').astype(float).fillna(0)
```
```python
                treatment_scores.append(col_numeric.iloc[:, 0])
```
```python
            else:
```
```python
                treatment_scores.append(df[col])
```

```python
        if treatment_scores:
```
```python
            df_new['ì¹˜ë£Œ_ê°•ë„_ì ìˆ˜'] = sum(treatment_scores)
```

> ğŸ’¬ 4. ë‚˜ì´ ê·¸ë£¹ ì¸ì½”ë”© (ìˆœì„œí˜•)

```python
    if 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´' in df.columns:
```
```python
        age_mapping = {
```
```python
            'ë§Œ18-34ì„¸': 1, 'ë§Œ35-37ì„¸': 2, 'ë§Œ38-39ì„¸': 3,
```
```python
            'ë§Œ40-42ì„¸': 4, 'ë§Œ43-44ì„¸': 5, 'ë§Œ45-50ì„¸': 6,
```
```python
            'ì•Œ ìˆ˜ ì—†ìŒ': 0
```
```python
        }
```
```python
        df_new['ë‚˜ì´_ê·¸ë£¹_ì ìˆ˜'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].map(age_mapping).fillna(0)
```

> ğŸ’¬ 5. ë¶ˆì„ ì›ì¸ ì¢…í•© ì ìˆ˜

```python
    infertility_cols = [col for col in df.columns if 'ë¶ˆì„ ì›ì¸' in col and df[col].dtype in ['int64', 'float64']]
```
```python
    if infertility_cols:
```
```python
        df_new['ë¶ˆì„_ì›ì¸_ì´ê°œìˆ˜'] = df[infertility_cols].sum(axis=1)
```

> ğŸ’¬ 6. ë°°ì•„/ë‚œì í’ˆì§ˆ ì§€í‘œ

```python
    if 'ì´ ìƒì„± ë°°ì•„ ìˆ˜' in df.columns and 'í˜¼í•©ëœ ë‚œì ìˆ˜' in df.columns:
```
> ğŸ’¬ ì „ì²´ì ì¸ ìƒì‹ ì„¸í¬ í™œìš©ë„

```python
        df_new['ìƒì‹ì„¸í¬_í™œìš©ë„'] = (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + df['í˜¼í•©ëœ ë‚œì ìˆ˜']) / 2
```

```python
    return df_new
```

> ğŸ’¬ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ ì ìš©

```python
print("ğŸ”¬ ë„ë©”ì¸ íŠ¹ì„± ìƒì„± ì¤‘...")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
X_engineered = add_engineered_features(X_processed)
```
```python
test_engineered = add_engineered_features(test_processed)
```

```python
new_features = set(X_engineered.columns) - set(X_processed.columns)
```
```python
print(f"âœ… ìƒì„±ëœ ìƒˆë¡œìš´ íŠ¹ì„±: {len(new_features)}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for feature in new_features:
```
```python
    print(f"   + {feature}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 5. ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ·ï¸ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
X_encoded = X_engineered.copy()
```
```python
test_encoded = test_engineered.copy()
```

> ğŸ’¬ ìˆœì„œê°€ ìˆëŠ” ë²”ì£¼í˜• ë³€ìˆ˜ë“¤ (ì´ë¯¸ ì²˜ë¦¬ë¨: ë‚˜ì´_ê·¸ë£¹_ì ìˆ˜)

```python
ordinal_features = ['ë‚˜ì´_ê·¸ë£¹_ì ìˆ˜'] if 'ë‚˜ì´_ê·¸ë£¹_ì ìˆ˜' in X_encoded.columns else []
```

> ğŸ’¬ ë‚˜ë¨¸ì§€ ë²”ì£¼í˜• ë³€ìˆ˜ë“¤

```python
remaining_categorical = [col for col in categorical_cols if col in X_encoded.columns and col not in ordinal_features]
```

> ğŸ’¬ Target Encoding ì ìš© (ì„±ëŠ¥ì´ ì¢‹ì€ ì¸ì½”ë”© ë°©ë²•)

```python
from sklearn.preprocessing import TargetEncoder
```

```python
if remaining_categorical:
```
```python
    print(f"ğŸ¯ Target Encoding ì ìš© ì¤‘... ({len(remaining_categorical)}ê°œ ë³€ìˆ˜)")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
    target_encoder = TargetEncoder(smooth=1.0, random_state=42)
```

> ğŸ’¬ í•™ìŠµ ë°ì´í„°ë¡œ í”¼íŒ…

```python
    X_encoded[remaining_categorical] = target_encoder.fit_transform(
```
```python
        X_encoded[remaining_categorical], y
```
```python
    )
```

> ğŸ’¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜

```python
    test_encoded[remaining_categorical] = target_encoder.transform(
```
```python
        test_encoded[remaining_categorical]
```
```python
    )
```

```python
    print("âœ… Target Encoding ì™„ë£Œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 6. ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ“ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìŠ¤ì¼€ì¼ë§")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ëª¨ë“  ë³€ìˆ˜ê°€ ì´ì œ ìˆ˜ì¹˜í˜•ì´ë¯€ë¡œ ìŠ¤ì¼€ì¼ë§ ì ìš©

```python
scaler = RobustScaler()  # ì´ìƒì¹˜ì— ê°•ê±´í•œ ìŠ¤ì¼€ì¼ëŸ¬
```

```python
X_scaled = pd.DataFrame(
```
```python
    scaler.fit_transform(X_encoded),
```
```python
    columns=X_encoded.columns,
```
```python
    index=X_encoded.index
```
```python
)
```

```python
test_scaled = pd.DataFrame(
```
```python
    scaler.transform(test_encoded),
```
```python
    columns=test_encoded.columns,
```
```python
    index=test_encoded.index
```
```python
)
```

```python
print(f"âœ… RobustScaler ì ìš© ì™„ë£Œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   íŠ¹ì„± ìˆ˜: {X_scaled.shape[1]}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 7. ë‹¤ì¤‘ê³µì„ ì„± í•´ê²° - ìƒê´€ê´€ê³„ ë†’ì€ ë³€ìˆ˜ ì œê±°

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ”— ë‹¤ì¤‘ê³µì„ ì„± í•´ê²°")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
correlation_matrix = X_scaled.corr().abs()
```
```python
high_corr_pairs = []
```

> ğŸ’¬ ìƒê´€ê´€ê³„ê°€ 0.9 ì´ìƒì¸ ë³€ìˆ˜ ìŒ ì°¾ê¸°

```python
for i in range(len(correlation_matrix.columns)):
```
```python
    for j in range(i+1, len(correlation_matrix.columns)):
```
```python
        if correlation_matrix.iloc[i, j] > 0.9:
```
```python
            high_corr_pairs.append({
```
```python
                'var1': correlation_matrix.columns[i],
```
```python
                'var2': correlation_matrix.columns[j],
```
```python
                'correlation': correlation_matrix.iloc[i, j]
```
```python
            })
```

```python
print(f"ë°œê²¬ëœ ê³ ìƒê´€ ë³€ìˆ˜ ìŒ: {len(high_corr_pairs)}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ìƒê´€ê´€ê³„ê°€ ë†’ì€ ë³€ìˆ˜ ì¤‘ í•˜ë‚˜ì”© ì œê±°

```python
cols_to_remove = []
```
```python
for pair in high_corr_pairs:
```
```python
    var1, var2 = pair['var1'], pair['var2']
```

> ğŸ’¬ íƒ€ê²Ÿê³¼ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¹„êµí•˜ì—¬ ë” ë‚®ì€ ê²ƒ ì œê±°

```python
    corr_y_var1 = abs(X_scaled[var1].corr(y))
```
```python
    corr_y_var2 = abs(X_scaled[var2].corr(y))
```

```python
    if corr_y_var1 < corr_y_var2 and var1 not in cols_to_remove:
```
```python
        cols_to_remove.append(var1)
```
```python
        print(f"   ì œê±°: {var1} (ìƒê´€: {pair['correlation']:.3f}, íƒ€ê²Ÿ ìƒê´€: {corr_y_var1:.3f})")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
    elif var2 not in cols_to_remove:
```
```python
        cols_to_remove.append(var2)
```
```python
        print(f"   ì œê±°: {var2} (ìƒê´€: {pair['correlation']:.3f}, íƒ€ê²Ÿ ìƒê´€: {corr_y_var2:.3f})")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ë³€ìˆ˜ ì œê±° ì ìš©

```python
if cols_to_remove:
```
```python
    X_final = X_scaled.drop(columns=cols_to_remove)
```
```python
    test_final = test_scaled.drop(columns=cols_to_remove)
```
```python
    print(f"\nâœ… ë‹¤ì¤‘ê³µì„ ì„± í•´ê²° ì™„ë£Œ: {len(cols_to_remove)}ê°œ ë³€ìˆ˜ ì œê±°")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
else:
```
```python
    X_final = X_scaled
```
```python
    test_final = test_scaled
```
```python
    print(f"\nâœ… ì œê±°í•  ê³ ìƒê´€ ë³€ìˆ˜ ì—†ìŒ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 8. ìµœì¢… ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ“‹ ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
preprocessing_summary = {
```
```python
    'ì›ë³¸_íŠ¹ì„±ìˆ˜': X.shape[1],
```
```python
    'ê³ ê²°ì¸¡_ì œê±°í›„': X_processed.shape[1],
```
```python
    'íŠ¹ì„±ì—”ì§€ë‹ˆì–´ë§í›„': X_engineered.shape[1],
```
```python
    'ìµœì¢…_íŠ¹ì„±ìˆ˜': X_final.shape[1],
```
```python
    'ì œê±°ëœ_íŠ¹ì„±ìˆ˜': X.shape[1] - X_final.shape[1],
```
```python
    'ì¶”ê°€ëœ_íŠ¹ì„±ìˆ˜': X_final.shape[1] - X_processed.shape[1]
```
```python
}
```

```python
print("ğŸ“Š íŠ¹ì„± ë³€í™”:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for key, value in preprocessing_summary.items():
```
```python
    print(f"   {key}: {value}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print(f"\nğŸ“ˆ ìµœì¢… ë°ì´í„° í˜•íƒœ:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   Train: {X_final.shape}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   Test: {test_final.shape}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   Target: {y.shape}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ë°ì´í„° í’ˆì§ˆ ì²´í¬

```python
print(f"\nğŸ” ë°ì´í„° í’ˆì§ˆ ì²´í¬:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   Train ê²°ì¸¡ì¹˜: {X_final.isnull().sum().sum()}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   Test ê²°ì¸¡ì¹˜: {test_final.isnull().sum().sum()}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ë¬´í•œê°’ ì—¬ë¶€: {np.isinf(X_final).sum().sum()}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print("\n" + "="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("âœ… 4ë‹¨ê³„ ì™„ë£Œ: ë°ì´í„° ì „ì²˜ë¦¬ ë° íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ”„ ë‹¤ìŒ ë‹¨ê³„: ëª¨ë¸ í•™ìŠµ ë° ì„±ëŠ¥ ìµœì í™”")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ë³€ìˆ˜ì— ì €ì¥ (ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì‚¬ìš©)

```python
print("\nğŸ’¾ ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("   ë³€ìˆ˜ëª…: X_final, test_final, y")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
# 5. 5ë‹¨ê³„: êµì°¨ê²€ì¦ ì½”ë“œ

### ğŸ”¹ ====================================================================

> ğŸ’¬ ì„ì‹  ì„±ê³µ ì—¬ë¶€ ì˜ˆì¸¡ ëª¨ë¸ - ìˆ˜ì •ëœ ë²„ì „

> ğŸ’¬ 5ë‹¨ê³„: ì˜¬ë°”ë¥¸ êµì°¨ê²€ì¦ìœ¼ë¡œ ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€

### ğŸ”¹ ====================================================================


```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ”§ 5ë‹¨ê³„ ìˆ˜ì •: ì˜¬ë°”ë¥¸ êµì°¨ê²€ì¦ íŒŒì´í”„ë¼ì¸")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ê¸°ì¡´ì˜ ì˜ëª»ëœ ì „ì²˜ë¦¬ëœ ë°ì´í„° ëŒ€ì‹  ì›ë³¸ì—ì„œ ë‹¤ì‹œ ì‹œì‘

```python
print("ğŸ“‚ ì›ë³¸ ë°ì´í„°ë¶€í„° ë‹¤ì‹œ ì‹œì‘...")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 1. ì›ë³¸ ë°ì´í„° ë¡œë“œ (4ë‹¨ê³„ ì´ˆê¸° ìƒíƒœ)

```python
train_raw = pd.read_csv('./train.csv').drop('ID', axis=1)
```
```python
test_raw = pd.read_csv('./test.csv').drop('ID', axis=1)
```

```python
X_raw = train_raw.drop('ì„ì‹  ì„±ê³µ ì—¬ë¶€', axis=1)
```
```python
y_raw = train_raw['ì„ì‹  ì„±ê³µ ì—¬ë¶€']
```

```python
print(f"ì›ë³¸ ë°ì´í„°: {X_raw.shape}, íƒ€ê²Ÿ: {y_raw.shape}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 2. ê³ ê²°ì¸¡ë¥  ë³€ìˆ˜ ì œê±° (ì´ê±´ ì•ˆì „í•¨)

```python
high_missing_cols = [
```
```python
    'ë‚œì í•´ë™ ê²½ê³¼ì¼', 'PGS ì‹œìˆ  ì—¬ë¶€', 'PGD ì‹œìˆ  ì—¬ë¶€',
```
```python
    'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', 'ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜', 'ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'
```
```python
]
```

```python
X_clean = X_raw.drop(columns=[col for col in high_missing_cols if col in X_raw.columns])
```
```python
test_clean = test_raw.drop(columns=[col for col in high_missing_cols if col in test_raw.columns])
```

```python
print(f"ê³ ê²°ì¸¡ ì œê±° í›„: {X_clean.shape}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 3. ì˜¬ë°”ë¥¸ êµì°¨ê²€ì¦ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤

```python
class ProperCrossValidationPipeline:
```
```python
    def __init__(self):
```
```python
        self.categorical_cols = []
```
```python
        self.numerical_cols = []
```
```python
        self.preprocessors = {}
```

```python
    def identify_column_types(self, X):
```
```python
        """ì»¬ëŸ¼ íƒ€ì… ìë™ ë¶„ë¥˜"""
```
```python
        categorical_cols = []
```
```python
        numerical_cols = []
```

```python
        for col in X.columns:
```
```python
            if X[col].dtype == 'object':
```
```python
                categorical_cols.append(col)
```
```python
            elif X[col].nunique() <= 10 and col.endswith(('ì—¬ë¶€', 'ì›ì¸', 'ìœ í˜•', 'íšŸìˆ˜', 'ì¶œì²˜', 'ë‚˜ì´')):
```
```python
                categorical_cols.append(col)
```
```python
            else:
```
```python
                numerical_cols.append(col)
```

```python
        return categorical_cols, numerical_cols
```

```python
    def preprocess_data(self, X_train, X_val, y_train, fit_preprocessors=True):
```
```python
        """ê° foldë§ˆë‹¤ ì˜¬ë°”ë¥´ê²Œ ì „ì²˜ë¦¬"""
```
```python
        X_train_processed = X_train.copy()
```
```python
        X_val_processed = X_val.copy()
```

```python
        if fit_preprocessors:
```
```python
            self.categorical_cols, self.numerical_cols = self.identify_column_types(X_train)
```

> ğŸ’¬ 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬

```python
        for col in self.categorical_cols:
```
```python
            if col in X_train_processed.columns:
```
```python
                if fit_preprocessors:
```
```python
                    mode_val = X_train_processed[col].mode()[0] if len(X_train_processed[col].mode()) > 0 else 'Unknown'
```
```python
                    self.preprocessors[f'{col}_mode'] = mode_val
```
```python
                else:
```
```python
                    mode_val = self.preprocessors[f'{col}_mode']
```

```python
                X_train_processed[col] = X_train_processed[col].fillna(mode_val)
```
```python
                X_val_processed[col] = X_val_processed[col].fillna(mode_val)
```

```python
        for col in self.numerical_cols:
```
```python
            if col in X_train_processed.columns:
```
```python
                if fit_preprocessors:
```
```python
                    median_val = X_train_processed[col].median()
```
```python
                    self.preprocessors[f'{col}_median'] = median_val
```
```python
                else:
```
```python
                    median_val = self.preprocessors[f'{col}_median']
```

```python
                X_train_processed[col] = X_train_processed[col].fillna(median_val)
```
```python
                X_val_processed[col] = X_val_processed[col].fillna(median_val)
```

> ğŸ’¬ 2. ê°„ë‹¨í•œ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (ì•ˆì „í•œ ê²ƒë“¤ë§Œ)

```python
        self.add_safe_features(X_train_processed)
```
```python
        self.add_safe_features(X_val_processed)
```

> ğŸ’¬ 3. Target Encoding (trainì—ì„œë§Œ í•™ìŠµ!)

```python
        remaining_categorical = [col for col in self.categorical_cols if col in X_train_processed.columns]
```

```python
        if remaining_categorical:
```
```python
            if fit_preprocessors:
```
> ğŸ’¬ train ë°ì´í„°ë¡œë§Œ target encoding í•™ìŠµ

```python
                self.preprocessors['target_encoder'] = TargetEncoder(smooth=1.0, random_state=42)
```
```python
                X_train_processed[remaining_categorical] = self.preprocessors['target_encoder'].fit_transform(
```
```python
                    X_train_processed[remaining_categorical], y_train
```
```python
                )
```
```python
            else:
```
```python
                X_train_processed[remaining_categorical] = self.preprocessors['target_encoder'].transform(
```
```python
                    X_train_processed[remaining_categorical]
```
```python
                )
```

> ğŸ’¬ validation ë°ì´í„°ëŠ” í•™ìŠµëœ ì¸ì½”ë”ë¡œë§Œ ë³€í™˜

```python
            X_val_processed[remaining_categorical] = self.preprocessors['target_encoder'].transform(
```
```python
                X_val_processed[remaining_categorical]
```
```python
            )
```

> ğŸ’¬ 4. ìŠ¤ì¼€ì¼ë§ (trainì—ì„œë§Œ í•™ìŠµ!)

```python
        if fit_preprocessors:
```
```python
            self.preprocessors['scaler'] = RobustScaler()
```
```python
            X_train_scaled = pd.DataFrame(
```
```python
                self.preprocessors['scaler'].fit_transform(X_train_processed),
```
```python
                columns=X_train_processed.columns,
```
```python
                index=X_train_processed.index
```
```python
            )
```
```python
        else:
```
```python
            X_train_scaled = pd.DataFrame(
```
```python
                self.preprocessors['scaler'].transform(X_train_processed),
```
```python
                columns=X_train_processed.columns,
```
```python
                index=X_train_processed.index
```
```python
            )
```

```python
        X_val_scaled = pd.DataFrame(
```
```python
            self.preprocessors['scaler'].transform(X_val_processed),
```
```python
            columns=X_val_processed.columns,
```
```python
            index=X_val_processed.index
```
```python
        )
```

```python
        return X_train_scaled, X_val_scaled
```

```python
    def add_safe_features(self, df):
```
```python
        """ì•ˆì „í•œ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (íƒ€ê²Ÿ ì •ë³´ ì‚¬ìš© ì•ˆí•¨)"""
```
> ğŸ’¬ 1. íš¨ìœ¨ì„± ì§€í‘œë“¤

```python
        if 'ì´ ìƒì„± ë°°ì•„ ìˆ˜' in df.columns and 'ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜' in df.columns:
```
```python
            df['ë°°ì•„_ìƒì„±_íš¨ìœ¨'] = df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] / (df['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'] + 1)
```

```python
        if 'ì´ì‹ëœ ë°°ì•„ ìˆ˜' in df.columns and 'ì´ ìƒì„± ë°°ì•„ ìˆ˜' in df.columns:
```
```python
            df['ë°°ì•„_ì´ì‹_ë¹„ìœ¨'] = df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] / (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)
```

> ğŸ’¬ 2. ë‚˜ì´ ê·¸ë£¹ ì ìˆ˜ (ìˆœì„œí˜•)

```python
        if 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´' in df.columns:
```
```python
            age_mapping = {
```
```python
                'ë§Œ18-34ì„¸': 1, 'ë§Œ35-37ì„¸': 2, 'ë§Œ38-39ì„¸': 3,
```
```python
                'ë§Œ40-42ì„¸': 4, 'ë§Œ43-44ì„¸': 5, 'ë§Œ45-50ì„¸': 6,
```
```python
                'ì•Œ ìˆ˜ ì—†ìŒ': 0
```
```python
            }
```
```python
            df['ë‚˜ì´_ê·¸ë£¹_ì ìˆ˜'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].map(age_mapping).fillna(0)
```

> ğŸ’¬ 4. ì˜¬ë°”ë¥¸ êµì°¨ê²€ì¦ ì‹¤í–‰

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ”„ ì˜¬ë°”ë¥¸ êµì°¨ê²€ì¦ ì‹œì‘")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
from sklearn.model_selection import StratifiedKFold
```
- `sklearn.model_selection`: í•™ìŠµìš©/ê²€ì¦ìš© ë°ì´í„° ë¶„í• , êµì°¨ ê²€ì¦, í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ë“±ì„ ì§€ì›í•©ë‹ˆë‹¤.
```python
from imblearn.over_sampling import SMOTE
```

```python
cv_folds = 5
```
```python
skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)
```

> ğŸ’¬ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”

```python
pipeline = ProperCrossValidationPipeline()
```

> ğŸ’¬ ê°„ë‹¨í•œ ëª¨ë¸ë“¤ë¡œ ë¨¼ì € í…ŒìŠ¤íŠ¸

```python
models = {
```
```python
    'LightGBM': lgb.LGBMClassifier(
```
```python
        random_state=42,
```
```python
        n_estimators=100,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì¤„ì„
```
```python
        learning_rate=0.1,
```
```python
        num_leaves=31,
```
```python
        verbose=-1
```
```python
    ),
```
```python
    'RandomForest': RandomForestClassifier(
```
```python
        random_state=42,
```
```python
        n_estimators=100,
```
```python
        max_depth=10,
```
```python
        min_samples_split=5
```
```python
    ),
```
```python
    'ExtraTrees': ExtraTreesClassifier(
```
```python
        random_state=42,
```
```python
        n_estimators=100,
```
```python
        max_depth=10,
```
```python
        min_samples_split=5
```
```python
    )
```
```python
}
```

```python
model_scores = {}
```

```python
print("ğŸš€ ì˜¬ë°”ë¥¸ êµì°¨ê²€ì¦ ì‹œì‘ (ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€)...")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
for name, model in models.items():
```
```python
    print(f"\nğŸ”„ {name} í•™ìŠµ ì¤‘...")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
    cv_scores = []
```

```python
    for fold, (train_idx, val_idx) in enumerate(skf.split(X_clean, y_raw)):
```
> ğŸ’¬ ë°ì´í„° ë¶„í• 

```python
        X_train_fold = X_clean.iloc[train_idx]
```
```python
        X_val_fold = X_clean.iloc[val_idx]
```
```python
        y_train_fold = y_raw.iloc[train_idx]
```
```python
        y_val_fold = y_raw.iloc[val_idx]
```

> ğŸ’¬ ê° foldë§ˆë‹¤ ìƒˆë¡œìš´ ì „ì²˜ë¦¬ (ì •ë³´ ëˆ„ì¶œ ë°©ì§€!)

```python
        X_train_processed, X_val_processed = pipeline.preprocess_data(
```
```python
            X_train_fold, X_val_fold, y_train_fold,
```
```python
            fit_preprocessors=(fold == 0)  # ì²« foldì—ì„œë§Œ íŒŒë¼ë¯¸í„° í•™ìŠµ
```
```python
        )
```

> ğŸ’¬ SMOTEë„ trainì—ì„œë§Œ ì ìš©

```python
        smote = SMOTE(random_state=42, k_neighbors=5)
```
```python
        X_train_balanced, y_train_balanced = smote.fit_resample(X_train_processed, y_train_fold)
```

> ğŸ’¬ ëª¨ë¸ í•™ìŠµ

```python
        model_copy = type(model)(**model.get_params())
```
```python
        model_copy.fit(X_train_balanced, y_train_balanced)
```

> ğŸ’¬ ì˜ˆì¸¡ ë° í‰ê°€ (ì›ë³¸ validation setìœ¼ë¡œ!)

```python
        y_pred_proba = model_copy.predict_proba(X_val_processed)[:, 1]
```
```python
        roc_auc = roc_auc_score(y_val_fold, y_pred_proba)
```

```python
        cv_scores.append(roc_auc)
```
```python
        print(f"   Fold {fold+1}: {roc_auc:.4f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
    avg_score = np.mean(cv_scores)
```
```python
    std_score = np.std(cv_scores)
```
```python
    model_scores[name] = {'mean': avg_score, 'std': std_score}
```

```python
    print(f"   âœ… í‰ê·  ROC-AUC: {avg_score:.4f} (Â±{std_score:.4f})")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 5. ê²°ê³¼ ë¹„êµ

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ† ìˆ˜ì •ëœ ê²°ê³¼")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
sorted_models = sorted(model_scores.items(), key=lambda x: x[1]['mean'], reverse=True)
```

```python
print("ğŸ“Š ROC-AUC ìˆœìœ„:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for rank, (name, scores) in enumerate(sorted_models, 1):
```
```python
    print(f"   {rank}. {name}: {scores['mean']:.4f} (Â±{scores['std']:.4f})")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
best_model_name = sorted_models[0][0]
```
```python
best_score = sorted_models[0][1]['mean']
```

```python
print(f"\nğŸ¯ ì´ì œ ì •ìƒì ì¸ ì ìˆ˜ê°€ ë‚˜ì™”ëŠ”ì§€ í™•ì¸:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ìµœê³  ì ìˆ˜: {best_score:.4f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
if best_score > 0.5:
```
```python
    print("   âœ… ì •ìƒì ì¸ ì ìˆ˜ì…ë‹ˆë‹¤! (0.5 ì´ìƒ)")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
    print("   ğŸš€ ì´ì œ ë³¸ê²©ì ì¸ ëª¨ë¸ íŠœë‹ ì§„í–‰ ê°€ëŠ¥")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
else:
```
```python
    print("   âš ï¸ ì—¬ì „íˆ ë‚®ì€ ì ìˆ˜... ì¶”ê°€ ë””ë²„ê¹… í•„ìš”")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print("\n" + "="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("âœ… ë°ì´í„° ë¦¬í‚¤ì§€ ìˆ˜ì • ì™„ë£Œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ”„ ì •ìƒ ì ìˆ˜ í™•ì¸ í›„ ë³¸ê²© íŠœë‹ ì§„í–‰")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
# 6. 6.ê³ ì„±ëŠ¥ ëª¨ë¸

### ğŸ”¹ ====================================================================

> ğŸ’¬ ìµœì¢… ê³ ì„±ëŠ¥ ì„ì‹  ì„±ê³µ ì˜ˆì¸¡ ëª¨ë¸ - ì™„ì „ì²´

> ğŸ’¬ ì˜¬ë°”ë¥¸ êµì°¨ê²€ì¦ + ê³ ê¸‰ íŠœë‹ + ì•™ìƒë¸”

### ğŸ”¹ ====================================================================


```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ† ìµœì¢… ê³ ì„±ëŠ¥ ëª¨ë¸ - ì™„ì „ì²´ ì‹œì‘")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 1. ë°ì´í„° ì¤€ë¹„ (ê²€ì¦ëœ ë°©ì‹)

```python
print("ğŸ“‚ ë°ì´í„° ì¤€ë¹„...")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
train_raw = pd.read_csv('./train.csv').drop('ID', axis=1)
```
```python
test_raw = pd.read_csv('./test.csv').drop('ID', axis=1)
```

```python
X_raw = train_raw.drop('ì„ì‹  ì„±ê³µ ì—¬ë¶€', axis=1)
```
```python
y_raw = train_raw['ì„ì‹  ì„±ê³µ ì—¬ë¶€']
```

> ğŸ’¬ ê³ ê²°ì¸¡ë¥  ë³€ìˆ˜ ì œê±°

```python
high_missing_cols = [
```
```python
    'ë‚œì í•´ë™ ê²½ê³¼ì¼', 'PGS ì‹œìˆ  ì—¬ë¶€', 'PGD ì‹œìˆ  ì—¬ë¶€',
```
```python
    'ì°©ìƒ ì „ ìœ ì „ ê²€ì‚¬ ì‚¬ìš© ì—¬ë¶€', 'ì„ì‹  ì‹œë„ ë˜ëŠ” ë§ˆì§€ë§‰ ì„ì‹  ê²½ê³¼ ì—°ìˆ˜', 'ë°°ì•„ í•´ë™ ê²½ê³¼ì¼'
```
```python
]
```

```python
X_clean = X_raw.drop(columns=[col for col in high_missing_cols if col in X_raw.columns])
```
```python
test_clean = test_raw.drop(columns=[col for col in high_missing_cols if col in test_raw.columns])
```

```python
print(f"âœ… ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ: {X_clean.shape}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 2. ê³ ê¸‰ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ í´ë˜ìŠ¤

```python
class AdvancedPreprocessingPipeline:
```
```python
    def __init__(self):
```
```python
        self.categorical_cols = []
```
```python
        self.numerical_cols = []
```
```python
        self.preprocessors = {}
```

```python
    def identify_column_types(self, X):
```
```python
        categorical_cols = []
```
```python
        numerical_cols = []
```

```python
        for col in X.columns:
```
```python
            if X[col].dtype == 'object':
```
```python
                categorical_cols.append(col)
```
```python
            elif X[col].nunique() <= 10 and col.endswith(('ì—¬ë¶€', 'ì›ì¸', 'ìœ í˜•', 'íšŸìˆ˜', 'ì¶œì²˜', 'ë‚˜ì´')):
```
```python
                categorical_cols.append(col)
```
```python
            else:
```
```python
                numerical_cols.append(col)
```

```python
        return categorical_cols, numerical_cols
```

```python
    def preprocess_data(self, X_train, X_val, y_train, fit_preprocessors=True):
```
```python
        X_train_processed = X_train.copy()
```
```python
        X_val_processed = X_val.copy()
```

```python
        if fit_preprocessors:
```
```python
            self.categorical_cols, self.numerical_cols = self.identify_column_types(X_train)
```

> ğŸ’¬ 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬

```python
        for col in self.categorical_cols:
```
```python
            if col in X_train_processed.columns:
```
```python
                if fit_preprocessors:
```
```python
                    mode_val = X_train_processed[col].mode()[0] if len(X_train_processed[col].mode()) > 0 else 'Unknown'
```
```python
                    self.preprocessors[f'{col}_mode'] = mode_val
```
```python
                else:
```
```python
                    mode_val = self.preprocessors[f'{col}_mode']
```

```python
                X_train_processed[col] = X_train_processed[col].fillna(mode_val)
```
```python
                X_val_processed[col] = X_val_processed[col].fillna(mode_val)
```

```python
        for col in self.numerical_cols:
```
```python
            if col in X_train_processed.columns:
```
```python
                if fit_preprocessors:
```
```python
                    median_val = X_train_processed[col].median()
```
```python
                    self.preprocessors[f'{col}_median'] = median_val
```
```python
                else:
```
```python
                    median_val = self.preprocessors[f'{col}_median']
```

```python
                X_train_processed[col] = X_train_processed[col].fillna(median_val)
```
```python
                X_val_processed[col] = X_val_processed[col].fillna(median_val)
```

> ğŸ’¬ 2. ê³ ê¸‰ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§

```python
        self.add_advanced_features(X_train_processed)
```
```python
        self.add_advanced_features(X_val_processed)
```

> ğŸ’¬ 3. Target Encoding

```python
        remaining_categorical = [col for col in self.categorical_cols if col in X_train_processed.columns]
```

```python
        if remaining_categorical:
```
```python
            if fit_preprocessors:
```
```python
                self.preprocessors['target_encoder'] = TargetEncoder(smooth=1.0, random_state=42)
```
```python
                X_train_processed[remaining_categorical] = self.preprocessors['target_encoder'].fit_transform(
```
```python
                    X_train_processed[remaining_categorical], y_train
```
```python
                )
```
```python
            else:
```
```python
                X_train_processed[remaining_categorical] = self.preprocessors['target_encoder'].transform(
```
```python
                    X_train_processed[remaining_categorical]
```
```python
                )
```

```python
            X_val_processed[remaining_categorical] = self.preprocessors['target_encoder'].transform(
```
```python
                X_val_processed[remaining_categorical]
```
```python
            )
```

> ğŸ’¬ 4. ìŠ¤ì¼€ì¼ë§

```python
        if fit_preprocessors:
```
```python
            self.preprocessors['scaler'] = RobustScaler()
```
```python
            X_train_scaled = pd.DataFrame(
```
```python
                self.preprocessors['scaler'].fit_transform(X_train_processed),
```
```python
                columns=X_train_processed.columns,
```
```python
                index=X_train_processed.index
```
```python
            )
```
```python
        else:
```
```python
            X_train_scaled = pd.DataFrame(
```
```python
                self.preprocessors['scaler'].transform(X_train_processed),
```
```python
                columns=X_train_processed.columns,
```
```python
                index=X_train_processed.index
```
```python
            )
```

```python
        X_val_scaled = pd.DataFrame(
```
```python
            self.preprocessors['scaler'].transform(X_val_processed),
```
```python
            columns=X_val_processed.columns,
```
```python
            index=X_val_processed.index
```
```python
        )
```

```python
        return X_train_scaled, X_val_scaled
```

```python
    def add_advanced_features(self, df):
```
```python
        """ê³ ê¸‰ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§"""
```
> ğŸ’¬ 1. íš¨ìœ¨ì„± ì§€í‘œë“¤

```python
        if 'ì´ ìƒì„± ë°°ì•„ ìˆ˜' in df.columns and 'ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜' in df.columns:
```
```python
            df['ë°°ì•„_ìƒì„±_íš¨ìœ¨'] = df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] / (df['ìˆ˜ì§‘ëœ ì‹ ì„  ë‚œì ìˆ˜'] + 1)
```

```python
        if 'ì´ì‹ëœ ë°°ì•„ ìˆ˜' in df.columns and 'ì´ ìƒì„± ë°°ì•„ ìˆ˜' in df.columns:
```
```python
            df['ë°°ì•„_ì´ì‹_ë¹„ìœ¨'] = df['ì´ì‹ëœ ë°°ì•„ ìˆ˜'] / (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)
```

```python
        if 'ì €ì¥ëœ ë°°ì•„ ìˆ˜' in df.columns and 'ì´ ìƒì„± ë°°ì•„ ìˆ˜' in df.columns:
```
```python
            df['ë°°ì•„_ë³´ì¡´_ë¹„ìœ¨'] = df['ì €ì¥ëœ ë°°ì•„ ìˆ˜'] / (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + 1)
```

> ğŸ’¬ 2. ë¯¸ì„¸ì£¼ì… ê´€ë ¨

```python
        if 'ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜' in df.columns and 'ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜' in df.columns:
```
```python
            df['ë¯¸ì„¸ì£¼ì…_ì„±ê³µë¥ '] = df['ë¯¸ì„¸ì£¼ì…ì—ì„œ ìƒì„±ëœ ë°°ì•„ ìˆ˜'] / (df['ë¯¸ì„¸ì£¼ì…ëœ ë‚œì ìˆ˜'] + 1)
```

> ğŸ’¬ 3. ì¢…í•© ì ìˆ˜ë“¤

```python
        if 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´' in df.columns:
```
```python
            age_mapping = {
```
```python
                'ë§Œ18-34ì„¸': 1, 'ë§Œ35-37ì„¸': 2, 'ë§Œ38-39ì„¸': 3,
```
```python
                'ë§Œ40-42ì„¸': 4, 'ë§Œ43-44ì„¸': 5, 'ë§Œ45-50ì„¸': 6,
```
```python
                'ì•Œ ìˆ˜ ì—†ìŒ': 0
```
```python
            }
```
```python
            df['ë‚˜ì´_ê·¸ë£¹_ì ìˆ˜'] = df['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].map(age_mapping).fillna(0)
```

> ğŸ’¬ 4. ë¶ˆì„ ì›ì¸ ì¢…í•©

```python
        infertility_cols = [col for col in df.columns if 'ë¶ˆì„ ì›ì¸' in col and df[col].dtype in ['int64', 'float64']]
```
```python
        if infertility_cols:
```
```python
            df['ë¶ˆì„_ì›ì¸_ì´ê°œìˆ˜'] = df[infertility_cols].sum(axis=1)
```

> ğŸ’¬ 5. ë°°ì•„/ë‚œì í’ˆì§ˆ ì§€í‘œ

```python
        if 'ì´ ìƒì„± ë°°ì•„ ìˆ˜' in df.columns and 'í˜¼í•©ëœ ë‚œì ìˆ˜' in df.columns:
```
```python
            df['ìƒì‹ì„¸í¬_í™œìš©ë„'] = (df['ì´ ìƒì„± ë°°ì•„ ìˆ˜'] + df['í˜¼í•©ëœ ë‚œì ìˆ˜']) / 2
```

> ğŸ’¬ 6. ì¹˜ë£Œ ì´ë ¥ ì ìˆ˜

```python
        treatment_cols = [col for col in df.columns if 'íšŸìˆ˜' in col and df[col].dtype == 'object']
```
```python
        if treatment_cols:
```
```python
            treatment_score = 0
```
```python
            for col in treatment_cols:
```
> ğŸ’¬ '0íšŒ', '1íšŒ' ë“±ì„ ìˆ«ìë¡œ ë³€í™˜

```python
                numeric_vals = df[col].str.extract(r'(\d+)').astype(float).fillna(0).iloc[:, 0]
```
```python
                treatment_score += numeric_vals
```
```python
            df['ì¹˜ë£Œ_ì´ë ¥_ì ìˆ˜'] = treatment_score
```

> ğŸ’¬ 3. ê³ ì„±ëŠ¥ ëª¨ë¸ë“¤ ì •ì˜

```python
models = {
```
```python
    'LightGBM_Tuned': lgb.LGBMClassifier(
```
```python
        random_state=42,
```
```python
        n_estimators=1000,
```
```python
        learning_rate=0.03,
```
```python
        num_leaves=63,
```
```python
        feature_fraction=0.8,
```
```python
        bagging_fraction=0.8,
```
```python
        min_child_samples=20,
```
```python
        reg_alpha=0.1,
```
```python
        reg_lambda=0.1,
```
```python
        verbose=-1
```
```python
    ),
```
```python
    'XGBoost_Tuned': xgb.XGBClassifier(
```
```python
        random_state=42,
```
```python
        n_estimators=1000,
```
```python
        learning_rate=0.03,
```
```python
        max_depth=8,
```
```python
        subsample=0.8,
```
```python
        colsample_bytree=0.8,
```
```python
        min_child_weight=3,
```
```python
        reg_alpha=0.1,
```
```python
        reg_lambda=0.1,
```
```python
        eval_metric='logloss'
```
```python
    ),
```
```python
    'RandomForest_Tuned': RandomForestClassifier(
```
```python
        random_state=42,
```
```python
        n_estimators=500,
```
```python
        max_depth=15,
```
```python
        min_samples_split=5,
```
```python
        min_samples_leaf=2,
```
```python
        max_features='sqrt',
```
```python
        class_weight='balanced'
```
```python
    ),
```
```python
    'ExtraTrees_Tuned': ExtraTreesClassifier(
```
```python
        random_state=42,
```
```python
        n_estimators=500,
```
```python
        max_depth=15,
```
```python
        min_samples_split=5,
```
```python
        min_samples_leaf=2,
```
```python
        max_features='sqrt',
```
```python
        class_weight='balanced'
```
```python
    ),
```
> ğŸ’¬ 'GradientBoosting_Tuned': GradientBoostingClassifier(

### ğŸ”¹ random_state=42,

### ğŸ”¹ n_estimators=300,

### ğŸ”¹ learning_rate=0.05,

### ğŸ”¹ max_depth=8,

### ğŸ”¹ subsample=0.8,

### ğŸ”¹ min_samples_split=10,

### ğŸ”¹ min_samples_leaf=5

> ğŸ’¬ )

```python
}
```

> ğŸ’¬ 4. ê³ ê¸‰ êµì°¨ê²€ì¦ ì‹¤í–‰

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸš€ ê³ ì„±ëŠ¥ ëª¨ë¸ êµì°¨ê²€ì¦ ì‹œì‘")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
cv_folds = 5
```
```python
skf = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)
```
```python
pipeline = AdvancedPreprocessingPipeline()
```

```python
model_scores = {}
```
```python
trained_models = {}
```

```python
for name, model in models.items():
```
```python
    print(f"\nğŸ”„ {name} í•™ìŠµ ì¤‘...")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
    cv_scores = []
```
```python
    fold_models = []
```

```python
    for fold, (train_idx, val_idx) in enumerate(skf.split(X_clean, y_raw)):
```
> ğŸ’¬ ë°ì´í„° ë¶„í• 

```python
        X_train_fold = X_clean.iloc[train_idx]
```
```python
        X_val_fold = X_clean.iloc[val_idx]
```
```python
        y_train_fold = y_raw.iloc[train_idx]
```
```python
        y_val_fold = y_raw.iloc[val_idx]
```

> ğŸ’¬ ì „ì²˜ë¦¬

```python
        X_train_processed, X_val_processed = pipeline.preprocess_data(
```
```python
            X_train_fold, X_val_fold, y_train_fold,
```
```python
            fit_preprocessors=(fold == 0)
```
```python
        )
```

> ğŸ’¬ SMOTE ì ìš©

```python
        smote = SMOTE(random_state=42, k_neighbors=5)
```
```python
        X_train_balanced, y_train_balanced = smote.fit_resample(X_train_processed, y_train_fold)
```

> ğŸ’¬ ëª¨ë¸ í•™ìŠµ

```python
        model_copy = type(model)(**model.get_params())
```
```python
        model_copy.fit(X_train_balanced, y_train_balanced)
```
```python
        fold_models.append(model_copy)
```

> ğŸ’¬ ì˜ˆì¸¡ ë° í‰ê°€

```python
        y_pred_proba = model_copy.predict_proba(X_val_processed)[:, 1]
```
```python
        roc_auc = roc_auc_score(y_val_fold, y_pred_proba)
```

```python
        cv_scores.append(roc_auc)
```

```python
        if fold < 2:  # ì²˜ìŒ 2ê°œ foldë§Œ ì¶œë ¥ (ì†ë„ í–¥ìƒ)
```
```python
            print(f"   Fold {fold+1}: {roc_auc:.4f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
    avg_score = np.mean(cv_scores)
```
```python
    std_score = np.std(cv_scores)
```
```python
    model_scores[name] = {'mean': avg_score, 'std': std_score}
```
```python
    trained_models[name] = fold_models
```

```python
    print(f"   âœ… í‰ê·  ROC-AUC: {avg_score:.4f} (Â±{std_score:.4f})")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 5. ê²°ê³¼ ë¹„êµ

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ† ìµœì¢… ëª¨ë¸ ì„±ëŠ¥ ìˆœìœ„")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
sorted_models = sorted(model_scores.items(), key=lambda x: x[1]['mean'], reverse=True)
```

```python
print("ğŸ“Š ROC-AUC ìˆœìœ„:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
for rank, (name, scores) in enumerate(sorted_models, 1):
```
```python
    print(f"   {rank}. {name}: {scores['mean']:.4f} (Â±{scores['std']:.4f})")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 6. ì•™ìƒë¸” êµ¬ì„± ë° ìµœì¢… ì˜ˆì¸¡

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ¤ ì•™ìƒë¸” ìµœì¢… ì˜ˆì¸¡")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ ìƒìœ„ 3ê°œ ëª¨ë¸ë¡œ ì•™ìƒë¸”

```python
top_3_models = [name for name, _ in sorted_models[:3]]
```
```python
print(f"ì•™ìƒë¸” êµ¬ì„±: {', '.join(top_3_models)}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡

```python
print("ğŸ”„ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡ ì¤‘...")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
final_predictions = []
```

```python
for fold in range(cv_folds):
```
> ğŸ’¬ ê° foldì˜ ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„° ì‚¬ìš©

```python
    pipeline_fold = AdvancedPreprocessingPipeline()
```

> ğŸ’¬ ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„° í•™ìŠµ

```python
    X_train_full_processed, _ = pipeline_fold.preprocess_data(
```
```python
        X_clean, X_clean.iloc[:100], y_raw, fit_preprocessors=True  # ë”ë¯¸ validation
```
```python
    )
```

> ğŸ’¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬

```python
    _, test_processed = pipeline_fold.preprocess_data(
```
```python
        X_clean, test_clean, y_raw, fit_preprocessors=False
```
```python
    )
```

> ğŸ’¬ ê° ëª¨ë¸ì˜ foldë³„ ì˜ˆì¸¡

```python
    fold_predictions = []
```
```python
    for model_name in top_3_models:
```
```python
        model = trained_models[model_name][fold]
```
```python
        pred_proba = model.predict_proba(test_processed)[:, 1]
```
```python
        fold_predictions.append(pred_proba)
```

> ğŸ’¬ ê°€ì¤‘ í‰ê·  (ì„±ëŠ¥ ê¸°ë°˜)

```python
    weights = [model_scores[name]['mean'] for name in top_3_models]
```
```python
    weights = np.array(weights) / sum(weights)
```

```python
    ensemble_pred = np.average(fold_predictions, axis=0, weights=weights)
```
```python
    final_predictions.append(ensemble_pred)
```

> ğŸ’¬ foldë³„ ì˜ˆì¸¡ì˜ í‰ê· 

```python
final_ensemble_pred = np.mean(final_predictions, axis=0)
```

> ğŸ’¬ 7. ì œì¶œ íŒŒì¼ ìƒì„±

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ“„ ì œì¶œ íŒŒì¼ ìƒì„±")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
test_ids = pd.read_csv('./test.csv')['ID']
```

```python
submission = pd.DataFrame({
```
```python
    'ID': test_ids,
```
```python
    'probability': final_ensemble_pred
```
```python
})
```

```python
submission_filename = 'final_high_performance_submission.csv'
```
```python
submission.to_csv(submission_filename, index=False)
```

```python
print(f"âœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {submission_filename}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ìƒ˜í”Œ ìˆ˜: {len(submission):,}ê°œ")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ì˜ˆì¸¡ í™•ë¥  ë²”ìœ„: {final_ensemble_pred.min():.4f} ~ {final_ensemble_pred.max():.4f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   í‰ê·  ì˜ˆì¸¡ í™•ë¥ : {final_ensemble_pred.mean():.4f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

> ğŸ’¬ 8. ìµœì¢… ì„±ê³¼ ìš”ì•½

```python
print("\n" + "="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ¯ ìµœì¢… ì„±ê³¼ ìš”ì•½")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*50)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
best_score = sorted_models[0][1]['mean']
```
```python
baseline_estimated = 0.55  # ë² ì´ìŠ¤ë¼ì¸ ExtraTreesClassifier ì¶”ì •ì¹˜
```

```python
improvement = ((best_score - baseline_estimated) / baseline_estimated) * 100
```

```python
print(f"ğŸš€ ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ê°œì„ ì‚¬í•­:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ğŸ“ˆ ë² ì´ìŠ¤ë¼ì¸ ì¶”ì • ì„±ëŠ¥: {baseline_estimated:.3f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ğŸ† ìµœì¢… ëª¨ë¸ ì„±ëŠ¥: {best_score:.4f}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ğŸ“Š ì„±ëŠ¥ í–¥ìƒ: +{improvement:.1f}%")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   ğŸ¤– ìµœì¢… ë°©ë²•: ìƒìœ„ 3ê°œ ëª¨ë¸ ê°€ì¤‘ ì•™ìƒë¸”")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print(f"\nğŸ”¬ ê¸°ìˆ ì  ê°œì„ ì‚¬í•­:")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   âœ… ë°ì´í„° ë¦¬í‚¤ì§€ ì™„ì „ ë°©ì§€")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   âœ… ê³ ê¸‰ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ (7ê°œ ë„ë©”ì¸ íŠ¹ì„±)")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   âœ… Target Encoding + RobustScaler")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   âœ… SMOTE ë¶ˆê· í˜• í•´ê²°")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   âœ… 5-Fold êµì°¨ê²€ì¦")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"   âœ… ê°€ì¤‘ ì•™ìƒë¸”")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.

```python
print("\n" + "="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ‰ ìµœì¢… ê³ ì„±ëŠ¥ ëª¨ë¸ ì™„ì„±!")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print(f"ğŸ“ ì œì¶œ íŒŒì¼: {submission_filename}")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("ğŸ† ë² ì´ìŠ¤ë¼ì¸ ëŒ€ë¹„ ëŒ€í­ ì„±ëŠ¥ í–¥ìƒ ë‹¬ì„±!")
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
```python
print("="*70)
```
- `print()`: ì½˜ì†”ì— ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ë””ë²„ê¹…ì´ë‚˜ ë¡œê¹…ìš©ìœ¼ë¡œ í™œìš©ë©ë‹ˆë‹¤.
